{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-GS Classifier\n",
    "### Attempt to label events with gluon splitting and differentiate types of gluon splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labels: 0 = noGS, 1 = GSb , 2 = GSbb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/rohan/code/gs_classifier/output_multigs.csv')\n",
    "\n",
    "feats = df.iloc[:,0:12]\n",
    "y = df.isgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1541, 12)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight</th>\n",
       "      <th>dr_bb</th>\n",
       "      <th>bb_pt</th>\n",
       "      <th>bb_m</th>\n",
       "      <th>jet1_csv</th>\n",
       "      <th>jet1_pt</th>\n",
       "      <th>jet1_eta</th>\n",
       "      <th>jet1_phi</th>\n",
       "      <th>jet2_csv</th>\n",
       "      <th>jet2_pt</th>\n",
       "      <th>jet2_eta</th>\n",
       "      <th>jet2_phi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.010080</td>\n",
       "      <td>3.168153</td>\n",
       "      <td>146.345215</td>\n",
       "      <td>1571.750244</td>\n",
       "      <td>0.991572</td>\n",
       "      <td>679.636658</td>\n",
       "      <td>0.259123</td>\n",
       "      <td>0.871540</td>\n",
       "      <td>0.962067</td>\n",
       "      <td>638.262634</td>\n",
       "      <td>-0.950709</td>\n",
       "      <td>-2.483592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010213</td>\n",
       "      <td>1.237230</td>\n",
       "      <td>568.637268</td>\n",
       "      <td>351.326141</td>\n",
       "      <td>0.952789</td>\n",
       "      <td>410.497620</td>\n",
       "      <td>1.856093</td>\n",
       "      <td>-3.062896</td>\n",
       "      <td>0.923160</td>\n",
       "      <td>164.860001</td>\n",
       "      <td>0.666116</td>\n",
       "      <td>-2.724229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.009712</td>\n",
       "      <td>0.956219</td>\n",
       "      <td>231.636139</td>\n",
       "      <td>115.960991</td>\n",
       "      <td>0.996852</td>\n",
       "      <td>84.478951</td>\n",
       "      <td>-0.129236</td>\n",
       "      <td>1.402133</td>\n",
       "      <td>0.888687</td>\n",
       "      <td>150.055801</td>\n",
       "      <td>-1.027457</td>\n",
       "      <td>1.730089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.009979</td>\n",
       "      <td>0.625336</td>\n",
       "      <td>884.483887</td>\n",
       "      <td>240.796066</td>\n",
       "      <td>0.963762</td>\n",
       "      <td>186.307327</td>\n",
       "      <td>1.013410</td>\n",
       "      <td>-2.106780</td>\n",
       "      <td>0.853772</td>\n",
       "      <td>702.267517</td>\n",
       "      <td>0.434318</td>\n",
       "      <td>-1.870778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010074</td>\n",
       "      <td>2.940529</td>\n",
       "      <td>277.393951</td>\n",
       "      <td>1224.259399</td>\n",
       "      <td>0.912212</td>\n",
       "      <td>710.185913</td>\n",
       "      <td>0.442450</td>\n",
       "      <td>-2.468202</td>\n",
       "      <td>0.896395</td>\n",
       "      <td>478.254578</td>\n",
       "      <td>-0.152350</td>\n",
       "      <td>0.411542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.009696</td>\n",
       "      <td>2.432887</td>\n",
       "      <td>490.836060</td>\n",
       "      <td>373.417236</td>\n",
       "      <td>0.961387</td>\n",
       "      <td>518.018860</td>\n",
       "      <td>0.913551</td>\n",
       "      <td>2.025568</td>\n",
       "      <td>0.904230</td>\n",
       "      <td>56.406910</td>\n",
       "      <td>-0.276445</td>\n",
       "      <td>-0.096424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.009766</td>\n",
       "      <td>2.399845</td>\n",
       "      <td>406.669495</td>\n",
       "      <td>385.500122</td>\n",
       "      <td>0.997387</td>\n",
       "      <td>69.960899</td>\n",
       "      <td>0.430898</td>\n",
       "      <td>-1.487286</td>\n",
       "      <td>0.953831</td>\n",
       "      <td>430.172821</td>\n",
       "      <td>-0.908712</td>\n",
       "      <td>2.804744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.009818</td>\n",
       "      <td>0.777033</td>\n",
       "      <td>424.745941</td>\n",
       "      <td>153.147583</td>\n",
       "      <td>0.996344</td>\n",
       "      <td>102.089409</td>\n",
       "      <td>-2.306477</td>\n",
       "      <td>1.622080</td>\n",
       "      <td>0.990068</td>\n",
       "      <td>336.790070</td>\n",
       "      <td>-1.818888</td>\n",
       "      <td>1.017070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.009587</td>\n",
       "      <td>1.345919</td>\n",
       "      <td>705.507812</td>\n",
       "      <td>225.399094</td>\n",
       "      <td>0.998911</td>\n",
       "      <td>44.010361</td>\n",
       "      <td>-0.281203</td>\n",
       "      <td>2.130650</td>\n",
       "      <td>0.918610</td>\n",
       "      <td>694.018066</td>\n",
       "      <td>-0.434562</td>\n",
       "      <td>-2.815382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.009960</td>\n",
       "      <td>3.212383</td>\n",
       "      <td>172.939484</td>\n",
       "      <td>539.344788</td>\n",
       "      <td>0.998345</td>\n",
       "      <td>143.079178</td>\n",
       "      <td>1.466260</td>\n",
       "      <td>-0.359827</td>\n",
       "      <td>0.870681</td>\n",
       "      <td>305.462006</td>\n",
       "      <td>-0.004287</td>\n",
       "      <td>3.067330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     weight     dr_bb       bb_pt         bb_m  jet1_csv     jet1_pt  \\\n",
       "0  0.010080  3.168153  146.345215  1571.750244  0.991572  679.636658   \n",
       "1  0.010213  1.237230  568.637268   351.326141  0.952789  410.497620   \n",
       "2  0.009712  0.956219  231.636139   115.960991  0.996852   84.478951   \n",
       "3  0.009979  0.625336  884.483887   240.796066  0.963762  186.307327   \n",
       "4  0.010074  2.940529  277.393951  1224.259399  0.912212  710.185913   \n",
       "5  0.009696  2.432887  490.836060   373.417236  0.961387  518.018860   \n",
       "6  0.009766  2.399845  406.669495   385.500122  0.997387   69.960899   \n",
       "7  0.009818  0.777033  424.745941   153.147583  0.996344  102.089409   \n",
       "8  0.009587  1.345919  705.507812   225.399094  0.998911   44.010361   \n",
       "9  0.009960  3.212383  172.939484   539.344788  0.998345  143.079178   \n",
       "\n",
       "   jet1_eta  jet1_phi  jet2_csv     jet2_pt  jet2_eta  jet2_phi  \n",
       "0  0.259123  0.871540  0.962067  638.262634 -0.950709 -2.483592  \n",
       "1  1.856093 -3.062896  0.923160  164.860001  0.666116 -2.724229  \n",
       "2 -0.129236  1.402133  0.888687  150.055801 -1.027457  1.730089  \n",
       "3  1.013410 -2.106780  0.853772  702.267517  0.434318 -1.870778  \n",
       "4  0.442450 -2.468202  0.896395  478.254578 -0.152350  0.411542  \n",
       "5  0.913551  2.025568  0.904230   56.406910 -0.276445 -0.096424  \n",
       "6  0.430898 -1.487286  0.953831  430.172821 -0.908712  2.804744  \n",
       "7 -2.306477  1.622080  0.990068  336.790070 -1.818888  1.017070  \n",
       "8 -0.281203  2.130650  0.918610  694.018066 -0.434562 -2.815382  \n",
       "9  1.466260 -0.359827  0.870681  305.462006 -0.004287  3.067330  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1541,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    0\n",
       "2    2\n",
       "3    0\n",
       "4    1\n",
       "5    0\n",
       "6    0\n",
       "7    0\n",
       "8    1\n",
       "9    1\n",
       "Name: isgs, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use K-folds for cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "n_folds = 5\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=452)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "#### Loop over the folds, train, and evaluate the decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cm_gs(mat, norm=False):\n",
    "    if mat.shape != (3,3): print(\"Matrix shape must be (3,3)\")\n",
    "        \n",
    "    cm_gs = mat\n",
    "    cm_gs[1,:]+=cm_gs[2,:]\n",
    "    cm_gs[:,1]+=cm_gs[:,2]\n",
    "    cm_gs = cm_gs[:2,:2]\n",
    "    \n",
    "    if norm:\n",
    "        return(cm_gs/cm_gs.sum(axis=1)[:, np.newaxis])\n",
    "    else:\n",
    "        return(cm_gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "\tTrain accuracy: 1.000\n",
      "\tTest accuracy: 0.461\n",
      "\n",
      "Fold 2:\n",
      "\tTrain accuracy: 1.000\n",
      "\tTest accuracy: 0.457\n",
      "\n",
      "Fold 3:\n",
      "\tTrain accuracy: 1.000\n",
      "\tTest accuracy: 0.467\n",
      "\n",
      "Fold 4:\n",
      "\tTrain accuracy: 1.000\n",
      "\tTest accuracy: 0.454\n",
      "\n",
      "Fold 5:\n",
      "\tTrain accuracy: 1.000\n",
      "\tTest accuracy: 0.471\n",
      "\n",
      "Mean train accuracy: 1.000\n",
      "Train CM:\n",
      " [[ 30.696   0.      0.   ]\n",
      " [  0.     21.555   0.   ]\n",
      " [  0.      0.     10.167]]\n",
      "\n",
      "Norm. Train CM:\n",
      " [[ 1.  0.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  0.  1.]]\n",
      "\n",
      "Mean test accuracy: 0.462\n",
      "Test CM:\n",
      " [[ 4.061  2.575  1.038]\n",
      " [ 2.374  2.247  0.768]\n",
      " [ 0.954  0.687  0.9  ]]\n",
      "\n",
      "Norm. Test CM:\n",
      " [[ 0.52916402  0.33558063  0.13525535]\n",
      " [ 0.44045138  0.41700554  0.14254309]\n",
      " [ 0.3754028   0.27046923  0.35412797]] \n",
      "\n",
      "Norm. Test CM GS:\n",
      " [[ 0.52916402  0.47083598]\n",
      " [ 0.41960348  0.58039652]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import label_binarize\n",
    "tree = DecisionTreeClassifier(random_state=368)\n",
    "cm_trains = np.zeros((3,3))\n",
    "cm_tests = np.zeros((3,3))\n",
    "for idx, (train, test) in enumerate(kf.split(feats, y)):\n",
    "    # Setup weights and train/test sets\n",
    "    train_weights = list(feats.iloc[train,0])\n",
    "    X_train, y_train = feats.iloc[train,1:12], y.iloc[train]\n",
    "    test_weights = list(feats.iloc[test,0])\n",
    "    X_test, y_test = feats.iloc[test, 1:12], y.iloc[test]\n",
    "    \n",
    "    # Train tree\n",
    "    tree.fit(X_train, y_train, sample_weight=train_weights)\n",
    "\n",
    "    # Evaluate with confusion matrix\n",
    "    # Print accuracy for each fold and the summed confusion matrix at the end\n",
    "    print(\"Fold {}:\").format(idx+1)\n",
    "\n",
    "    cm_train = confusion_matrix(y_train, tree.predict(X_train), sample_weight=train_weights)\n",
    "    print(\"\\tTrain accuracy: {:.3f}\").format(cm_train.trace()/cm_train.sum())\n",
    "    cm_trains += cm_train\n",
    "    \n",
    "    cm_test = confusion_matrix(y_test, tree.predict(X_test), sample_weight=test_weights)\n",
    "    print(\"\\tTest accuracy: {:.3f}\\n\").format(cm_test.trace()/cm_test.sum())\n",
    "    cm_tests += cm_test\n",
    "    \n",
    "print(\"Mean train accuracy: {:.3f}\").format(cm_trains.trace()/cm_trains.sum())\n",
    "print(\"Train CM:\\n {}\\n\").format(cm_trains.round(3))\n",
    "print(\"Norm. Train CM:\\n {}\\n\").format(cm_trains/cm_trains.sum(axis=1))\n",
    "print(\"Mean test accuracy: {:.3f}\").format(cm_tests.trace()/cm_tests.sum())\n",
    "print(\"Test CM:\\n {}\\n\").format(cm_tests.round(3))\n",
    "print(\"Norm. Test CM:\\n {} \\n\").format(cm_tests/cm_tests.sum(axis=1)[:, np.newaxis])\n",
    "print(\"Norm. Test CM GS:\\n {}\").format(get_cm_gs(cm_tests,True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Limiting Max DepthÂ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth 1:\n",
      "Mean train accuracy: 0.511\n",
      "Mean test accuracy: 0.485\n",
      "Mean test gs accuracy: 0.561\n",
      "\n",
      "Test CM:\n",
      " [[ 5.285  2.389  0.   ]\n",
      " [ 4.455  3.475  0.   ]\n",
      " [ 1.35   1.191  0.   ]]\n",
      "\n",
      "Norm. Test CM:\n",
      " [[ 0.68869675  0.31130325  0.        ]\n",
      " [ 0.56175892  0.43824108  0.        ]\n",
      " [ 0.53128345  0.46871655  0.        ]] \n",
      "\n",
      "Norm. Test CM GS:\n",
      " [[ 0.68869675  0.31130325]\n",
      " [ 0.55436223  0.44563777]]\n",
      "\n",
      "[ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "\n",
      "Depth 2:\n",
      "Mean train accuracy: 0.534\n",
      "Mean test accuracy: 0.525\n",
      "Mean test gs accuracy: 0.633\n",
      "\n",
      "Test CM:\n",
      " [[ 3.85   3.824  1.803]\n",
      " [ 1.906  6.024  3.362]\n",
      " [ 0.547  1.995  1.836]]\n",
      "\n",
      "Norm. Test CM:\n",
      " [[ 0.40625684  0.4035235   0.19021966]\n",
      " [ 0.16881081  0.53349363  0.29769556]\n",
      " [ 0.12485444  0.4557478   0.41939776]] \n",
      "\n",
      "Norm. Test CM GS:\n",
      " [[ 0.40625684  0.59374316]\n",
      " [ 0.15653064  0.84346936]]\n",
      "\n",
      "[ 0.          0.          0.48947408  0.51052592  0.          0.          0.\n",
      "  0.          0.          0.          0.        ]\n",
      "\n",
      "Depth 3:\n",
      "Mean train accuracy: 0.580\n",
      "Mean test accuracy: 0.524\n",
      "Mean test gs accuracy: 0.603\n",
      "\n",
      "Test CM:\n",
      " [[ 4.707  2.967  0.848]\n",
      " [ 3.222  4.709  1.977]\n",
      " [ 0.881  1.661  1.198]]\n",
      "\n",
      "Norm. Test CM:\n",
      " [[ 0.55234579  0.34817345  0.09948076]\n",
      " [ 0.32517608  0.47527887  0.19954505]\n",
      " [ 0.2355051   0.44418745  0.32030745]] \n",
      "\n",
      "Norm. Test CM GS:\n",
      " [[ 0.55234579  0.44765421]\n",
      " [ 0.3006048   0.6993952 ]]\n",
      "\n",
      "[ 0.          0.          0.48926128  0.38732282  0.12341589  0.          0.\n",
      "  0.          0.          0.          0.        ]\n",
      "\n",
      "Depth 4:\n",
      "Mean train accuracy: 0.607\n",
      "Mean test accuracy: 0.531\n",
      "Mean test gs accuracy: 0.576\n",
      "\n",
      "Test CM:\n",
      " [[ 5.761  1.913  0.439]\n",
      " [ 4.698  3.232  1.208]\n",
      " [ 1.383  1.159  0.829]]\n",
      "\n",
      "Norm. Test CM:\n",
      " [[ 0.71002831  0.23582797  0.05414372]\n",
      " [ 0.51410813  0.3536583   0.13223357]\n",
      " [ 0.41024201  0.34382595  0.24593204]] \n",
      "\n",
      "Norm. Test CM GS:\n",
      " [[ 0.71002831  0.28997169]\n",
      " [ 0.48612194  0.51387806]]\n",
      "\n",
      "[ 0.08520045  0.0137794   0.36240426  0.28689669  0.09141628  0.          0.\n",
      "  0.09989998  0.06040295  0.          0.        ]\n",
      "\n",
      "Depth 5:\n",
      "Mean train accuracy: 0.640\n",
      "Mean test accuracy: 0.515\n",
      "Mean test gs accuracy: 0.574\n",
      "\n",
      "Test CM:\n",
      " [[ 4.743  2.931  0.504]\n",
      " [ 3.72   4.211  1.26 ]\n",
      " [ 1.101  1.44   0.889]]\n",
      "\n",
      "Norm. Test CM:\n",
      " [[ 0.57997492  0.35843345  0.06159163]\n",
      " [ 0.40471621  0.45816337  0.13712041]\n",
      " [ 0.32104413  0.41982925  0.25912662]] \n",
      "\n",
      "Norm. Test CM GS:\n",
      " [[ 0.57997492  0.42002508]\n",
      " [ 0.38197293  0.61802707]]\n",
      "\n",
      "[ 0.10103912  0.07884777  0.27868128  0.22061754  0.0702972   0.04073325\n",
      "  0.01415147  0.09215122  0.06132548  0.04215567  0.        ]\n",
      "\n",
      "Depth 6:\n",
      "Mean train accuracy: 0.688\n",
      "Mean test accuracy: 0.508\n",
      "Mean test gs accuracy: 0.567\n",
      "\n",
      "Test CM:\n",
      " [[ 4.871  2.803  0.764]\n",
      " [ 3.954  3.977  1.435]\n",
      " [ 1.193  1.349  0.932]]\n",
      "\n",
      "Norm. Test CM:\n",
      " [[ 0.57730049  0.33217984  0.09051968]\n",
      " [ 0.42217716  0.42459067  0.15323217]\n",
      " [ 0.34332824  0.38838205  0.26828971]] \n",
      "\n",
      "Norm. Test CM GS:\n",
      " [[ 0.57730049  0.42269951]\n",
      " [ 0.40084467  0.59915533]]\n",
      "\n",
      "[ 0.1000163   0.07733385  0.26942312  0.16460133  0.10547173  0.04196431\n",
      "  0.0316244   0.08585462  0.04575455  0.04631238  0.0316434 ]\n",
      "\n",
      "Depth 7:\n",
      "Mean train accuracy: 0.742\n",
      "Mean test accuracy: 0.513\n",
      "Mean test gs accuracy: 0.593\n",
      "\n",
      "Test CM:\n",
      " [[ 4.541  3.133  0.885]\n",
      " [ 3.222  4.709  1.808]\n",
      " [ 0.905  1.637  1.104]]\n",
      "\n",
      "Norm. Test CM:\n",
      " [[ 0.53055573  0.36602013  0.10342414]\n",
      " [ 0.33080152  0.48352496  0.18567351]\n",
      " [ 0.24817895  0.44906277  0.30275829]] \n",
      "\n",
      "Norm. Test CM GS:\n",
      " [[ 0.53055573  0.46944427]\n",
      " [ 0.30829796  0.69170204]]\n",
      "\n",
      "[ 0.12345613  0.07001012  0.22400102  0.15230037  0.10726128  0.05518869\n",
      "  0.04705646  0.12170118  0.04112514  0.03307037  0.02482924]\n",
      "\n",
      "Depth 8:\n",
      "Mean train accuracy: 0.794\n",
      "Mean test accuracy: 0.485\n",
      "Mean test gs accuracy: 0.566\n",
      "\n",
      "Test CM:\n",
      " [[ 4.212  3.462  0.944]\n",
      " [ 3.313  4.617  1.705]\n",
      " [ 0.895  1.647  1.044]]\n",
      "\n",
      "Norm. Test CM:\n",
      " [[ 0.48871958  0.40169398  0.10958643]\n",
      " [ 0.34386859  0.4791758   0.17695561]\n",
      " [ 0.24953318  0.45932041  0.29114641]] \n",
      "\n",
      "Norm. Test CM GS:\n",
      " [[ 0.48871958  0.51128042]\n",
      " [ 0.31828441  0.68171559]]\n",
      "\n",
      "[ 0.10841265  0.08007589  0.17700413  0.12928529  0.12685593  0.06934913\n",
      "  0.0525196   0.12901121  0.05034649  0.03263655  0.04450313]\n",
      "\n",
      "Depth 9:\n",
      "Mean train accuracy: 0.846\n",
      "Mean test accuracy: 0.488\n",
      "Mean test gs accuracy: 0.570\n",
      "\n",
      "Test CM:\n",
      " [[ 4.12   3.554  0.914]\n",
      " [ 3.153  4.777  1.728]\n",
      " [ 0.916  1.626  1.034]]\n",
      "\n",
      "Norm. Test CM:\n",
      " [[ 0.47970959  0.41381954  0.10647088]\n",
      " [ 0.326463    0.4946569   0.1788801 ]\n",
      " [ 0.25613779  0.45468457  0.28917763]] \n",
      "\n",
      "Norm. Test CM GS:\n",
      " [[ 0.47970959  0.52029041]\n",
      " [ 0.3074615   0.6925385 ]]\n",
      "\n",
      "[ 0.09268437  0.1050436   0.14751264  0.11663517  0.13378377  0.07626517\n",
      "  0.0534118   0.11721677  0.0542038   0.0439786   0.0592643 ]\n",
      "\n",
      "Depth 10:\n",
      "Mean train accuracy: 0.894\n",
      "Mean test accuracy: 0.472\n",
      "Mean test gs accuracy: 0.556\n",
      "\n",
      "Test CM:\n",
      " [[ 4.157  3.518  0.926]\n",
      " [ 3.416  4.514  1.641]\n",
      " [ 0.983  1.559  0.948]]\n",
      "\n",
      "Norm. Test CM:\n",
      " [[ 0.48333008  0.40902451  0.10764541]\n",
      " [ 0.35688099  0.47163589  0.17148311]\n",
      " [ 0.28171498  0.44672394  0.27156108]] \n",
      "\n",
      "Norm. Test CM GS:\n",
      " [[ 0.48333008  0.51666992]\n",
      " [ 0.33680065  0.66319935]]\n",
      "\n",
      "[ 0.10541104  0.1001341   0.14927849  0.11106919  0.12773108  0.07815003\n",
      "  0.05057386  0.11699989  0.05985304  0.04316719  0.05763207]\n",
      "\n",
      "Depth 11:\n",
      "Mean train accuracy: 0.928\n",
      "Mean test accuracy: 0.472\n",
      "Mean test gs accuracy: 0.556\n",
      "\n",
      "Test CM:\n",
      " [[ 4.025  3.649  1.035]\n",
      " [ 3.274  4.657  1.682]\n",
      " [ 0.933  1.609  0.988]]\n",
      "\n",
      "Norm. Test CM:\n",
      " [[ 0.46217358  0.41897547  0.11885095]\n",
      " [ 0.34053998  0.48444037  0.17501966]\n",
      " [ 0.26431324  0.45585538  0.27983138]] \n",
      "\n",
      "Norm. Test CM GS:\n",
      " [[ 0.46217358  0.53782642]\n",
      " [ 0.32006952  0.67993048]]\n",
      "\n",
      "[ 0.10428909  0.09885218  0.14474424  0.1144258   0.12882939  0.09026076\n",
      "  0.05907902  0.11209302  0.05228321  0.04403031  0.05111299]\n",
      "\n",
      "Depth 12:\n",
      "Mean train accuracy: 0.955\n",
      "Mean test accuracy: 0.465\n",
      "Mean test gs accuracy: 0.554\n",
      "\n",
      "Test CM:\n",
      " [[ 4.113  3.561  1.036]\n",
      " [ 3.401  4.529  1.623]\n",
      " [ 0.954  1.588  0.91 ]]\n",
      "\n",
      "Norm. Test CM:\n",
      " [[ 0.47220061  0.40887974  0.11891965]\n",
      " [ 0.35603744  0.47410518  0.16985738]\n",
      " [ 0.2762935   0.46016943  0.26353707]] \n",
      "\n",
      "Norm. Test CM GS:\n",
      " [[ 0.47220061  0.52779939]\n",
      " [ 0.33487425  0.66512575]]\n",
      "\n",
      "[ 0.1044312   0.08701043  0.13976975  0.10593535  0.13347076  0.0822289\n",
      "  0.06820747  0.11522381  0.06438353  0.04391093  0.05542787]\n",
      "\n",
      "Depth 13:\n",
      "Mean train accuracy: 0.973\n",
      "Mean test accuracy: 0.460\n",
      "Mean test gs accuracy: 0.555\n",
      "\n",
      "Test CM:\n",
      " [[ 3.982  3.692  1.126]\n",
      " [ 3.253  4.677  1.697]\n",
      " [ 0.934  1.608  0.91 ]]\n",
      "\n",
      "Norm. Test CM:\n",
      " [[ 0.45250512  0.4195561   0.12793877]\n",
      " [ 0.33790981  0.48582712  0.17626307]\n",
      " [ 0.27051184  0.46591975  0.26356841]] \n",
      "\n",
      "Norm. Test CM GS:\n",
      " [[ 0.45250512  0.54749488]\n",
      " [ 0.32012415  0.67987585]]\n",
      "\n",
      "[ 0.1044677   0.08022102  0.1453053   0.10266026  0.1259025   0.0970868\n",
      "  0.06386541  0.11109323  0.05344767  0.04799673  0.06795338]\n",
      "\n",
      "Depth 14:\n",
      "Mean train accuracy: 0.983\n",
      "Mean test accuracy: 0.467\n",
      "Mean test gs accuracy: 0.563\n",
      "\n",
      "Test CM:\n",
      " [[ 3.99   3.684  1.12 ]\n",
      " [ 3.136  4.794  1.735]\n",
      " [ 0.875  1.666  0.95 ]]\n",
      "\n",
      "Norm. Test CM:\n",
      " [[ 0.45372624  0.41887583  0.12739793]\n",
      " [ 0.32448481  0.49597421  0.17954098]\n",
      " [ 0.25068554  0.47717209  0.27214237]] \n",
      "\n",
      "Norm. Test CM GS:\n",
      " [[ 0.45372624  0.54627376]\n",
      " [ 0.30489898  0.69510102]]\n",
      "\n",
      "[ 0.10964696  0.08667192  0.13724102  0.10170047  0.11792645  0.09761418\n",
      "  0.0696547   0.10246251  0.05051666  0.05674833  0.0698168 ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "depth_trees = []\n",
    "for depth in range(1,15):\n",
    "    print(\"Depth {}:\").format(depth)\n",
    "    tree = DecisionTreeClassifier(random_state=368, max_depth=depth)\n",
    "    cm_trains = np.zeros((3,3))\n",
    "    cm_tests = np.zeros((3,3))\n",
    "    for idx, (train, test) in enumerate(kf.split(feats, y)):\n",
    "        # Setup weights and train/test sets\n",
    "        train_weights = list(feats.iloc[train,0])\n",
    "        X_train, y_train = feats.iloc[train,1:12], y.iloc[train]\n",
    "        test_weights = list(feats.iloc[test,0])\n",
    "        X_test, y_test = feats.iloc[test, 1:12], y.iloc[test]\n",
    "    \n",
    "        # Train tree\n",
    "        tree.fit(X_train, y_train, sample_weight=train_weights)\n",
    "\n",
    "        # Evaluate with confusion matrix\n",
    "        # Print accuracy for each fold and the summed confusion matrix at the end\n",
    "        cm_train = confusion_matrix(y_train, tree.predict(X_train), sample_weight=train_weights)\n",
    "        cm_trains += cm_train\n",
    "    \n",
    "        cm_test = confusion_matrix(y_test, tree.predict(X_test), sample_weight=test_weights)\n",
    "        cm_tests += cm_test\n",
    "    \n",
    "    print(\"Mean train accuracy: {:.3f}\").format(cm_trains.trace()/cm_trains.sum())\n",
    "    print(\"Mean test accuracy: {:.3f}\").format(cm_tests.trace()/cm_tests.sum())\n",
    "\n",
    "    mat_cm_gs = get_cm_gs(cm_tests)\n",
    "    print(\"Mean test gs accuracy: {:.3f}\\n\").format(mat_cm_gs.trace()/mat_cm_gs.sum())\n",
    "    \n",
    "    print(\"Test CM:\\n {}\\n\").format(cm_tests.round(3))\n",
    "    print(\"Norm. Test CM:\\n {} \\n\").format(cm_tests/cm_tests.sum(axis=1)[:, np.newaxis])\n",
    "    print(\"Norm. Test CM GS:\\n {}\\n\").format(get_cm_gs(cm_tests,True))\n",
    "    print(\"{}\\n\").format(tree.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The classifiers seem to prefer bb_m and jet1_csv as the most important variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show>"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11fa8a3d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df[df.isgs==0].bb_m, alpha=0.5, label='noGS', log=True, normed=True)\n",
    "plt.hist(df[df.isgs==1].bb_m, alpha=0.5, label='GSb', normed=True)\n",
    "plt.hist(df[df.isgs==2].bb_m, alpha=0.5, label='GSbb', normed=True)\n",
    "plt.legend(loc='upper right')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show>"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11faf32d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df[df.isgs==0].jet1_csv, alpha=0.5, label='noGS', log=True, normed=True)\n",
    "plt.hist(df[df.isgs==1].jet1_csv, alpha=0.5, label='GSb', normed=True)\n",
    "plt.hist(df[df.isgs==2].jet1_csv, alpha=0.5, label='GSbb', normed=True)\n",
    "plt.legend(loc='upper left')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
